{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/voice-cloning-finetune/TTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
    "from TTS.tts.datasets import load_tts_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Found 2390 files in /home/voice-cloning-finetune/ThaiMultiSpeech\n"
     ]
    }
   ],
   "source": [
    "# dataset config for one of the pre-defined datasets\n",
    "ds_path = \"/home/voice-cloning-finetune/ThaiMultiSpeech\"\n",
    "dataset_config = BaseDatasetConfig(\n",
    "    formatter=\"tms_formatter\", meta_file_train=\"metadata.txt\", path=ds_path, language=\"th\"\n",
    ")\n",
    "\n",
    "# load training samples\n",
    "train_samples, eval_samples = load_tts_samples(dataset_config, eval_split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'พอเข้ามาในห้องคุณสาย แม่ก็หยิบหมอนออกมาจากหลังตู้ใบหนึ่ง เอามาวางลงกับพื้นกระดาน แล้วแม่ก็เสื่อมตัวลงนอนอีกสักครู่ก็หลับอย่างสบาย ส่วนคุณสายก็กลับมานั่งที่เดิม หยิบผ้าห่มที่ซักแล้วมากองหนึ่ง บอกว่าเป็นของเสด็จ แล้วก็เรียกร้องให้เข้าไปนั่งใกล้ ๆ แล้วบอกให้ช่วยกันจีบ โดยคุณสายทําให้ดูก่อน แล้วก็ให้พลอยลองทําดูบ้าง',\n",
       "  'audio_file': '/home/voice-cloning-finetune/ThaiMultiSpeech/wavs/เจ้าคุณพระ_sample0_chunk179.wav',\n",
       "  'speaker_name': 'เจ้าคุณพระ',\n",
       "  'root_path': '/home/voice-cloning-finetune/ThaiMultiSpeech',\n",
       "  'language': 'th',\n",
       "  'audio_unique_name': '#wavs/เจ้าคุณพระ_sample0_chunk179'},\n",
       " {'text': 'การดึงเสื้อสวมเข้าทางหัวของเขาเท่าไหร่ เสื้อก็ยิ่งหดเล็กลงเล็กลง จนกระทั่งในที่สุดมันเล็กจนแทบจะใส่ให้ตุ๊กตาหุ่นมือได้พอดี ซึ่งแน่นอนย่อมไม่พอดีกับแฮร์รี่ ป้าเพชรธูเนียสรุปว่า มันคงหดตอนที่เธอเอาไปซัก และแฮร์รี่ก็โล่งใจที่ไม่ถูกลงโทษ',\n",
       "  'audio_file': '/home/voice-cloning-finetune/ThaiMultiSpeech/wavs/Understand Thai_sample1_chunk134.wav',\n",
       "  'speaker_name': 'Understand Thai',\n",
       "  'root_path': '/home/voice-cloning-finetune/ThaiMultiSpeech',\n",
       "  'language': 'th',\n",
       "  'audio_unique_name': '#wavs/Understand Thai_sample1_chunk134'},\n",
       " {'text': 'เจ้าเป็นสายลมไม่ได้ เราเป็นสองอย่างที่แตกต่างกัน สายลมบอกไม่จริงเลย ฉันได้เรียนรู้จากความลับของนักแปลทักษะระหว่างการเดินทาง ฉันมีสายลมทะเลทรายมหาสมุทร ดาวและสิ่งมีชีวิตอยู่ในตัวฉัน เราต่างถูกสร้างขึ้นโดยพระหัตถ์ของพระเจ้าเดียวกันและมีวิญญาณเดียวกัน ฉันอยากจะเป็นอย่างท่าน ฉันอยากเดินทางไป',\n",
       "  'audio_file': '/home/voice-cloning-finetune/ThaiMultiSpeech/wavs/นิยาย ก่อนนอน_sample0_chunk442.wav',\n",
       "  'speaker_name': 'นิยาย ก่อนนอน',\n",
       "  'root_path': '/home/voice-cloning-finetune/ThaiMultiSpeech',\n",
       "  'language': 'th',\n",
       "  'audio_unique_name': '#wavs/นิยาย ก่อนนอน_sample0_chunk442'},\n",
       " {'text': 'คนที่ตายก็คือเจ้าตังค์ เพราะข้ารู้ว่าจะเปลี่ยนตัวเองเป็นสายลมได้อย่างไร ในวันที่สอง เด็กหนุ่มปีนไปบนหน้าผาที่อยู่ข้างค่ายทหาร ยามอนุญาตให้เขาขึ้นไปได้ พวกยามก็ได้ยินเรื่องของพ่อมดผู้แปลงเป็นสายลมได้ และไม่อยากเข้าใกล้เขาถึงยังไง เด็กหนุ่มก็ฝ่าทะเลทรายไปไม่ได้อยู่ดี เขาใช้เวลาตลอดบ่ายของวันที่สอง มองทะเลทรายและฟังเสียงจากหัวใจของเขา',\n",
       "  'audio_file': '/home/voice-cloning-finetune/ThaiMultiSpeech/wavs/นิยาย ก่อนนอน_sample0_chunk431.wav',\n",
       "  'speaker_name': 'นิยาย ก่อนนอน',\n",
       "  'root_path': '/home/voice-cloning-finetune/ThaiMultiSpeech',\n",
       "  'language': 'th',\n",
       "  'audio_unique_name': '#wavs/นิยาย ก่อนนอน_sample0_chunk431'},\n",
       " {'text': 'พอแม่ถามแม่ก็ตอบเอง เหมือนกับว่าคงจะเดาออกว่าในบ้านนี้ ถ้าจะมีคนให้ของพรอย ก็น่าจะเป็นคุณเฉย นี่แหละ พรอยได้แต่พยักหน้ารับคํา แม่กําลังปิดหีบอยู่ ก็หยุดนิ่ง เอามือวางพัดไว้บนฝาหีบครู่หนึ่ง ตาเมมมองออกไปนอกหน้าต่างเหมือนกําลังตื่นตรองตัดสินใจอะไรอยู่ แต่แล้วแม่ก็ถอนใจใหญ่สลัดหน้า',\n",
       "  'audio_file': '/home/voice-cloning-finetune/ThaiMultiSpeech/wavs/เจ้าคุณพระ_sample0_chunk51.wav',\n",
       "  'speaker_name': 'เจ้าคุณพระ',\n",
       "  'root_path': '/home/voice-cloning-finetune/ThaiMultiSpeech',\n",
       "  'language': 'th',\n",
       "  'audio_unique_name': '#wavs/เจ้าคุณพระ_sample0_chunk51'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train TorToise Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TortoiseConfig: all model related values for training, validating and testing.\n",
    "from TTS.tts.configs.shared_configs import CharactersConfig\n",
    "from TTS.tts.configs.glow_tts_config import GlowTTSConfig\n",
    "from TTS.tts.models.glow_tts import GlowTTS\n",
    "from TTS.config.shared_configs import BaseAudioConfig\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "from TTS.tts.utils.speakers import SpeakerManager\n",
    "from trainer import Trainer, TrainerArgs\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the following code in `/usr/local/lib/python3.9/dist-packages/TTS/tts/utils/text/cleaners.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pythainlp.tokenize import word_tokenize\n",
    "\n",
    "# def thai_cleaners(text):\n",
    "#     \"\"\"Pipeline for Thai text\"\"\"\n",
    "#     text = lowercase(text)\n",
    "#     text = replace_symbols(text, lang=None)\n",
    "#     text = remove_aux_symbols(text)\n",
    "#     text = ' '.join(word_tokenize(text, keep_whitespace=False))\n",
    "#     return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Thai cleaners on transcription sample\n",
    "# thai_cleaners(train_samples[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"glowtts_train_dir\"\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_config = BaseAudioConfig(sample_rate=22050, resample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_config = CharactersConfig(\n",
    "    pad=\"_\",\n",
    "    eos=\"&\",\n",
    "    bos=\"*\",\n",
    "    blank=None,\n",
    "    characters=\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\\u0e01\\u0e02\\u0e03\\u0e04\\u0e05\\u0e06\\u0e07\\u0e08\\u0e09\\u0e0a\\u0e0b\\u0e0c\\u0e0d\\u0e0e\\u0e0f\\u0e10\\u0e11\\u0e12\\u0e13\\u0e14\\u0e15\\u0e16\\u0e17\\u0e18\\u0e19\\u0e1a\\u0e1b\\u0e1c\\u0e1d\\u0e1e\\u0e1f\\u0e20\\u0e21\\u0e22\\u0e23\\u0e24\\u0e25\\u0e26\\u0e27\\u0e28\\u0e29\\u0e2a\\u0e2b\\u0e2c\\u0e2d\\u0e2e\\u0e30\\u0e31\\u0e32\\u0e33\\u0e34\\u0e35\\u0e36\\u0e37\\u0e38\\u0e39\\u0e3a\\u0e40\\u0e41\\u0e42\\u0e43\\u0e44\\u0e45\\u0e46\\u0e47\\u0e48\\u0e49\\u0e4a\\u0e4b\\u0e4c\\u0e4d\\u0e4e\\u0e4f\\u0e50\\u0e51\\u0e52\\u0e53\\u0e54\\u0e55\\u0e56\\u0e57\\u0e58\\u0e59\",\n",
    "    punctuations=\"!'(),-.:;? \",\n",
    "    phonemes=\"\",\n",
    "    is_unique=True,\n",
    "    is_sorted=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GlowTTSConfig(\n",
    "    batch_size=4,\n",
    "    eval_batch_size=2,\n",
    "    num_loader_workers=1,\n",
    "    num_eval_loader_workers=1,\n",
    "    run_eval=True,\n",
    "    test_delay_epochs=-1,\n",
    "    epochs=100,\n",
    "    audio=audio_config,\n",
    "    text_cleaner=\"thai_cleaners\",\n",
    "    use_speaker_embedding=True,\n",
    "    use_phonemes=False,\n",
    "    print_step=25,\n",
    "    print_eval=False,\n",
    "    mixed_precision=True,\n",
    "    output_path=output_path,\n",
    "    datasets=[dataset_config],\n",
    "    characters=char_config,\n",
    "    save_step=1000,\n",
    "    training_seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:True\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:45\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n"
     ]
    }
   ],
   "source": [
    "ap = AudioProcessor.init_from_config(config)\n",
    "# Modify sample rate if for a custom audio dataset:\n",
    "# ap.sample_rate = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, config = TTSTokenizer.init_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init speaker manager for multi-speaker training\n",
    "# it maps speaker-id to speaker-name in the model and data-loader\n",
    "speaker_manager = SpeakerManager()\n",
    "speaker_manager.set_ids_from_data(train_samples + eval_samples, parse_key=\"speaker_name\")\n",
    "config.num_speakers = speaker_manager.num_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Found 2390 files in /home/voice-cloning-finetune/ThaiMultiSpeech\n"
     ]
    }
   ],
   "source": [
    "train_samples, eval_samples = load_tts_samples(\n",
    "    dataset_config,\n",
    "    eval_split=True,\n",
    "    eval_split_max_size=config.eval_split_max_size,\n",
    "    eval_split_size=config.eval_split_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Init speaker_embedding layer.\n"
     ]
    }
   ],
   "source": [
    "model = GlowTTS(config, ap, tokenizer, speaker_manager=speaker_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any parent up to mount point /home)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "fatal: not a git repository (or any parent up to mount point /home)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 500: named symbol not found (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      " > Training Environment:\n",
      " | > Backend: Torch\n",
      " | > Mixed precision: True\n",
      " | > Precision: fp16\n",
      " | > Num. of CPUs: 8\n",
      " | > Num. of Torch Threads: 4\n",
      " | > Torch seed: 42\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " | > Torch TF32 MatMul: False\n",
      " > Start Tensorboard: tensorboard --logdir=glowtts_train_dir/run-October-21-2024_08+44AM-0000000\n",
      "\n",
      " > Model has 32340433 parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > `speakers.pth` is saved to glowtts_train_dir/run-October-21-2024_08+44AM-0000000/speakers.pth.\n",
      " > `speakers_file` is updated in the config.json.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/100\u001b[0m\n",
      " --> glowtts_train_dir/run-October-21-2024_08+44AM-0000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "| > Number of instances : 2367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m > TRAINING (2024-10-21 08:44:36) \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Preprocessing samples\n",
      " | > Max text length: 551\n",
      " | > Min text length: 5\n",
      " | > Avg text length: 275.29446556822984\n",
      " | \n",
      " | > Max audio length: 1487988\n",
      " | > Min audio length: 208538\n",
      " | > Avg audio length: 1372787.1081537812\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m   --> TIME: 2024-10-21 08:44:56 -- STEP: 0/592 -- GLOBAL_STEP: 0\u001b[0m\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 18.5631  (18.563103675842285)\n",
      "     | > loader_time: 1.2964  (1.296417474746704)\n",
      "\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      "/home/voice-cloning-finetune/TTS/TTS/tts/models/glow_tts.py:415: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=False):  # avoid mixed_precision in criterion\n"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
